---
title: "two-stage-inference-alternate"
author: "Brian N. White"
date: "2022-05-11"
output: html_document
---

```{r, set global code chunk options, include = F}
knitr::opts_chunk$set(fig.align = 'center', warning = F, message = F, tidy = TRUE) # centers figures generated by code chunks
```

```{r load packages}
library(tidyverse) # data manipulation meta-package
library(Matrix) # for use in computing Kronecker product
library(blockmatrix) # compute block matrices
library(mvtnorm) # compute MVN density
library(extRemes) # compute MLE of GEV model
library(geosphere) # used to compute geodesic distance between lat-lon pairs
library(gstat) # for (universal) kriging
library(sp) # for manipulating spatial data
library(plotly) # for 3D scatterplots
```

```{r import data}
# data covers FEMA region 3
df_meta_region3 <- read.csv('data/df_meta_region3.csv') # lat-lon data
ADC_POST_Detided_region3 <- read.csv('data/ADC_POST_Detided_region3.csv') #  modeled (ADCIRC) data
NOAA_OBS_Detided_region3 <- read.csv('data/NOAA_OBS_Detided_region3.csv') # observed (NOAA) data
```

```{r clean data}
source('./functions/clean_timeseries.R') # converts time to POSIX class, adds variables month & year, replace station ID with station name
source('./functions/clean_metadata.R') # remove white space from station names

df_meta_region3 <- clean_metadata(df_meta_region3) # remove white space from station names


ADC_POST_Detided_region3 <- clean_timeseries(timeseries = ADC_POST_Detided_region3, 
                                             metadata = df_meta_region3 
                                                            %>% filter(stationname != 'Lewisetta')
                                             )

NOAA_OBS_Detided_region3 <- clean_timeseries(timeseries = NOAA_OBS_Detided_region3, metadata = df_meta_region3) %>%
                              select(-Lewisetta) %>% # exclude Lewisetta for consistency with ADCIRC data
                              select(c(1:3, 29:4)) # re-arrange stations to match order of columns in ADC_POST_Detided_region3

df_meta_region3 <- df_meta_region3 %>% 
                          filter(stationname != 'Lewisetta') # remove Lewisetta from meta data
```

```{r compute yearly maxima for each station}
# create data frame with yearly maxima for each station
 df_max <- ADC_POST_Detided_region3 %>% 
  select(-TIME, -month) %>%
  group_by(year) %>%
  summarise_all(max, na.rm = T) %>%
  mutate(year = as.numeric(year))
```

```{r 1st stage of inference: station-by-station non-stationary GEV fit}
gev_results <- list() # list to store independent GEV fits for each station

# fit and store the models in the prepared list
for(i in 2:ncol(df_max)) {
  gev_results[[i-1]] <- fevd(df_max[[i]], use.phi = T, type = 'GEV') # phi = T means log(sigma) used instead of sigma
}

names(gev_results) <- colnames(df_max)[-1] # add station names to results

# compute and store the GEV parameter MLEs
par_results <- list()

for(i in 1:length(gev_results)) {
  
  par_results[[i]] <- gev_results[[i]]$results$par
  
}

names(par_results) <- colnames(df_max)[-1] # add station names to results

# compute and store the estimated co-variance matrices
cov_results <- list()

for(i in 1:length(gev_results)) {
   
  cov_results[[i]] <- solve(gev_results[[i]]$results$hessian)
  
}

names(cov_results) <- colnames(df_max)[-1] # add station names to results
```

```{r specify model hyper parameters: L, d, and p}
L <- nrow(df_meta_region3) # number of spatial locations

d <- 3 # dimension of spatial process

# total number of parameters in model to be estimated
p <- 2*d + d*(d + 1)/2 # first term includes the mean and range parameters, second term the co-regionalization parameters

# examine growth of parameter space dimension as the dimension of the spatial process increases
p_function <- function(x) 2*x + x*(x + 1)/2

tibble(x = 1:20, y = p_function(x)) %>% 
  ggplot(aes(x = x, y = y)) +
  geom_line(size = 0.3, col = 'blue') +
  labs(x = 'Dimension of Gaussian process', y = '# of parameters') +
  scale_y_continuous(breaks = seq(0, 250, by = 25)) 
```

```{r compute data vector: theta_hat}
# compute data vector of MLEs for gev parameters
theta_hat <- vector()

# order one location after the other
  for(i in 1:L) { # each location

  theta_hat <- c(theta_hat, par_results[[i]])

  }
  
theta_hat
```

```{r compute distance matrix: dist_matrix}
dist_matrix <- df_meta_region3 %>%
  select(lon, lat) %>%
  slice(26:1) %>% # re-arrange stations to match order of parameters fit by fevd
  distm(fun = distHaversine)/10000 # great-circle-distance via haversine method, assumes spherical earth

rownames(dist_matrix) <- colnames(df_max[, -1])
colnames(dist_matrix) <- colnames(df_max[, -1])
```

```{r compute variance matrix for measurement error process: W}
W <- bdiag(cov_results) %>% as.matrix()
```

```{r compute variance matrix for spatially correlated random effects: S}
S <- function(A, rho, dist) {
  
  V <- list()
  
  for(i in 1:L) {
    
    storage <- list()
    
    for(j in 1:L) {
      
      S <- diag(d)
      
      for(k in 1:d) {
        
        S[k, k] <- exp(-dist_matrix[i, j]/rho[k])
        
      }
      
     C <- A %*% S %*% t(A)
     
     storage[[j]] <- C
      
    }
    
    row_cov <- Reduce(cbind, storage)
    
    V[[i]] <- row_cov
    
  }
  
  result <- Reduce(rbind, V)
  
  return(result)
  
}
```


```{r compute Gaussian process likelihood}
# par = parameters, W = error covariance, dist = station by station distances
gaussian_process_likelihood <- function(par, data,  W, dist) {

# co-regionalization matrix used to define S below 
A <- matrix(0, nrow = d, ncol = d)
A[upper.tri(A, diag = TRUE)] <- par[(d + 1):(p - d)]
A <- t(A)

# variance matrix for spatially correlated random effects
S <- S(A, par[(p - d + 1):p], dist)

# mean vector  of the MVN density
mu <- rep(par[1:d], L)

# variance matrix of the MVN density
V <- S + W 
  
# MVVN negative log-likelihood
log_lik <- -(L*d/2)*log(2*pi) - (1/2)*log(det(V)) - (1/2)*t(data - mu) %*% solve(V) %*% (data - mu)
result <- -log_lik

# alternatively, use MVN density from mvtnorm package
# result <- -dmvnorm(data, mean = mu, sigma = S + W, log = T)
  
return(result)

}
```

```{r 2nd stage of inference: given theta_hat and W; find beta, A and rho}
start_time <- Sys.time() # track run time of optim

# fit p dimensional Gaussian process with assumed form of W
gaussian_process_fit <-  optim(c(runif(p - d, 0.1, 100), runif(d, 50, max(dist_matrix))), 
                               gaussian_process_likelihood, 
                               data = theta_hat, W = W, 
                               dist = dist_matrix, 
                               method = 'BFGS', 
                               hessian = T, 
                               control=list(maxit = 10000))

# c(runif(p - d, 0.1, 100), runif(d, 50, max(dist_matrix)))

end_time <- Sys.time()
run_time <- end_time-start_time

run_time

# extract the mean parameter values over R^2
beta <- gaussian_process_fit$par[1:d]

# extract A, the co-regionalization  lower diagonal matrix
A <- matrix(0, nrow = d, ncol = d)
A[upper.tri(A, diag = TRUE)] <- gaussian_process_fit$par[(d + 1):(p - d)]
A <- t(A)

# extract range parameters
rho <- gaussian_process_fit$par[(p - d + 1):p]

# extract covariance matrix
min_eigen_cov <- ifelse(min(eigen(solve(gaussian_process_fit$hessian))$values) > 0, 'Yes', 'No')

# organize results
gaussian_results <- list(beta, A, rho, min_eigen_cov)
names(gaussian_results) <- c('beta: mean parameter values over R^2', 
                             'A: co-regionalization matrix', 
                             'rho: range parameters',
                             'Is approximate co-variance matrix of MLE positive semi-definite?')

gaussian_results
```

```{r implement kriging}
# theta_hat is output from 1st stage of inference, par is output from second stage, W is error process covariance
kriging_pred <- function(new_loc, theta_hat, rho, A, W) {

  V <- S(A, rho, dist_matrix)
  sigma_inv <- solve(V + W) # plug-in MLE estimate of covariance matrix for theta hat

  beta_hat <- gaussian_results$`beta: mean parameter values over R^2`
  
  tau <- matrix(rep(0, d*L), nrow = d, ncol = d*L) # compute covariance of new location and theta hat
  
  storage <- list()
  
   for(i in 1:L) { # for each location
     
     C <- diag(d) # covariance matrix for new obs and location i
     
     for(j in 1:d) { # for each spatial process
       
       C[j, j] <- exp(-distHaversine(new_loc, df_meta_region3[27 - i, 4:3])*(10^-3)/rho[j])
       
     }
     
     storage[[i]] <-  A %*% C %*% t(A)
     
   }
  
  tau <- Reduce(cbind, storage) # covariance matrix of new location with existence locations
  
  pred <- beta_hat + tau %*% sigma_inv %*% (theta_hat - rep(beta_hat, L))
  
  cov <- A %*% t(A) - tau %*% sigma_inv %*% t(tau)
    
  rownames(pred) <- c('location', 'log.scale', 'shape')
  
  result <- list(pred, cov)
  names(result) <- c('predictions', 'covariance')
  
  return(result)

}
```

```{r compute kriging predictions and covariances for known stations}
check <- list()

for(i in 1:L) {
  
check[[i]] <- kriging_pred(df_meta_region3[27 - i, 4:3], 
              theta_hat, 
              gaussian_results$`rho: range parameters`, 
              gaussian_results$`A: co-regionalization matrix`,
              W)

}
  
names(check) <- colnames(df_max[,-1])

for(i in 1:L) {
  
  print(check[i])
  print(par_results[i])
  
}


coastline <- tibble(lon = seq(-79, -72, length.out = length(seq(30, 41, by = 0.1))), 
                    lat = seq(30, 41, by = 0.1))
    
coastline_storage <- list()

for(i in 1:nrow(coastline)) {
  coastline_storage[[i]] <- kriging_pred(coastline[i, ], theta_hat, gaussian_results$`rho: range parameters`, gaussian_results$`A: co-regionalization matrix`, W)
}
```

```{r implement return levels}
return_levels <- function(par, cov, p) {
  
  scale <- exp(par[2])
  
  y_p <- -log(1 - p) # 1/p return level, where p is the upper tail probability: see Coles (2001) page 56,
  
  if (abs(par[3]) > 0.001 ) { # if the shape parameter is not about zero
    
  z_p <- par[1] - (scale/par[3])*(1 - y_p^(-par[3]))
  
  } else { # if the she parameter is about zero
    
  z_p <- par[1] - scale*log(y_p)
    
  }
  
  # compute variance for z_p
  
    # compute gradient of z_p via delta-method approximation
    z_p_grad <- c(1, 
               -par[3]^(-1)*(1 - y_p^-par[3]), 
                scale*par[3]^(-2)*(1 - y_p^-par[3]) - scale*par[3]^(-1)*y_p^(-par[3])*log(y_p))
  
    z_p_var <- t(z_p_grad) %*% cov %*% z_p_grad

 result <- list(z_p, sqrt(z_p_var))
 names(result) <- c('1/p return level', 'sd')
 
 return(result)
  
}
```

```{r compute return levels and variances}
v1 <- vector() # storage for 1/p return levels
v2 <- vector() # storage for corresponding sd

for(i in 1:nrow(coastline)) {
v1[i] <- return_levels(coastline_storage[[i]][[1]], coastline_storage[[i]][[2]], 1/20)$'1/p return level'
v2[i] <- return_levels(coastline_storage[[i]][[1]], coastline_storage[[i]][[2]], 1/20)$'sd'
}

return_level_results <- tibble(return_levels = v1, sd = v2, lower95 = v1 - qnorm(.975)*v2, upper95 = v1 + qnorm(.975)*v1, lon = coastline$lon, lat = coastline$lat)
```

```{r produce return level plots, warning = F}
states <- map_data("state")

east_coast <- states %>%
  filter(region %in% c('florida', 'georgia', 'south carolina', 'north carolina', 'virginia', 'district of columbia', 'pennsylvania', 'maryland', 'delaware', 'new jersey', 'connecticut', 'new york', 'rhode island', 'massachusetts', 'vermont', 'new hampshire', 'maine' ))

ggplot() + 
  geom_polygon(data = east_coast, aes(x = long, y = lat, group = group), color = "white") +
  geom_point(data = df_meta_region3, aes(x = lon, y = lat), col = 'black', size = 0.01) +
  geom_point(data = return_level_results, aes(x = lon, y = lat, color = return_levels)) + 
  geom_text(data = df_meta_region3, aes(x = lon, y = lat, label = stationname), size = 2.5, col = 'red', check_overlap = T) +
  labs(title = '1/p return levels along U.S. East Coast')
  guides(fill = F)
  
plot_ly(return_level_results, 
        x = ~lon, 
        y = ~lat, 
        z = ~return_levels, 
        mode = 'markers', 
        type = 'scatter3d', 
        marker = list(size = 1, symbol = 104)) %>%
  add_trace(data = return_level_results, 
            x = ~lon, 
            y = ~lat, 
            z = ~upper95,
            mode = "markers", 
            type = "scatter3d", 
            marker = list(size = 1, color = "red", symbol = 104)) %>%
    add_trace(data = return_level_results, 
            x = ~lon, 
            y = ~lat, 
            z = ~lower95,
            mode = "markers", 
            type = "scatter3d", 
            marker = list(size = 1, color = "red", symbol = 104))
  
```