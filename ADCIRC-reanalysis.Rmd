---
title: "ADCIRC Reanalysis"
author: "Brian N. White"
date: "2/19/2022"
output:
  pdf_document: default
  html_document: default
---

```{r, include = F}
knitr::opts_chunk$set(fig.align = 'center', warning = F, message = F, tidy=TRUE)
```


```{r, include = F}
# data wrangling
library(tidyverse)
library(reshape2)

# extreme value analysis
library(extRemes)
library(SpatialExtremes)

# working with spatial data
library(maps)
library(ggmap)
library(sf)
```


### Data Description

1. df_meta_region3.csv: Contains identifying information for each NOAA sea-level observation station (i.e. lat/lon coordinates, state, node, name, id). There are 26 rows and 6 columns. Each row is a station, each column an identifying feature. The stations range the majority of the U.S. East Coast but the focus is FEMA region 3.

2. ADC_POST_Detided_region3.csv: Contains hourly ADC_POST_Detided time-series data for each NOAA sea-level observation station. The time-series spans the 40-year period from 1979-01-01 01:00:00 to 2019-12-31 23:00:00. There are 359400 rows and 28 columns. Each row is an hourly observation and, except for TIME and year, each column is a station,

3. ADC_NOAA_OBS_region3.csv: Identical structure as ADC_POST_Detided_region3 but for hourly NOAA_OBS_Detided time-series data.

### Data Wrangling

```{r import and clean data, warning = F, message = F}
# load data
df_meta_region3 <- read.csv('data/df_meta_region3.csv')
ADC_POST_Detided_region3 <- read.csv('data/ADC_POST_Detided_region3.csv')
NOAA_OBS_Detided_region3 <- read.csv('data/NOAA_OBS_Detided_region3.csv')
```


```{r clean data, warning = F, message = F}
# Lewisetta was excluded from ADC_POST_Detided before import so remove from df_meta_region3 and   NOAA_OBS_Detided_region3 for consistency

# pull Lewisetta's station id
raw_Lewisetta_station_id <- df_meta_region3 %>%
    filter(stationname == !!'Lewisetta') %>%
    select(stationid) %>%
    pull()

# add X to beginning of station id to match column name in ADC_POST_Detided
Lewisetta_station_id <- paste('X', raw_Lewisetta_station_id, sep = '')

# remove Lewisetta from NOAA_OBS_Detided_region3
NOAA_OBS_Detided_region3 <- NOAA_OBS_Detided_region3 %>%
  select(-Lewisetta_station_id)

# remove Lewisetta from df_meta_region3
df_meta_region3 <- df_meta_region3 %>%
  filter(stationname != 'Lewisetta')

# Now, clean meta data
clean_metadata <- function(metadata) {

  # remove white-space from station names as this can lead to conflicts with ggplot
  metadata$stationname <- str_replace_all(metadata$stationname, " ", "")
  
  return(metadata)

}

# Then, clean the time-series
clean_timeseries <- function(timeseries, metadata) {
  
  # coerce time variable to POSIX class
   timeseries$TIME <- as.POSIXct(timeseries$TIME, format = "%Y-%m-%d %H:%M:%S")
  
  # create year and month variables from TIME column
  timeseries <- add_column(timeseries,  year = format(timeseries$TIME, '%Y'), month = format(timeseries$TIME,    '%m'), .after = 1)
  
  # rename columns with station name
  for(station in metadata$stationname){

    # extract station id
    raw_station_id <- metadata %>%
    filter(stationname == !!station) %>%
    select(stationid) %>%
    pull()

  # add an X to the beginning to match current variable names
  station_id <- paste('X', raw_station_id, sep = '')

  # rename columns for ease of use
  timeseries <- timeseries %>%
    rename(!!station := station_id)
  }
  
  return(timeseries)

}

# clean meta data and corresponding time-series under consideration
df_meta_region3 <- clean_metadata(df_meta_region3)
ADC_POST_Detided_region3 <- clean_timeseries(ADC_POST_Detided_region3, df_meta_region3)
NOAA_OBS_Detided_region3 <- clean_timeseries(NOAA_OBS_Detided_region3, df_meta_region3)
```

```{r check for missing values, warning = F}
# computes the number of NA values
sum_na <- function(x) sum(is.na(x))

# computes proportion of NA values
prop_na <- function(x) sum_na(x)/length(x)

# computes row index of NA values
which_na <- function(x) which(is.na(x) == T)

# if the proportion of NA values in a station (whether overall or within a year) exceeds this then it will be flagged for removal
overview_na <- function(timeseries, threshold, group_by_year = F) {
  
  if(group_by_year == F) {

        # computes the proportion of NA values as each station and then returns T or F if value exceeds threshold
        df1 <- timeseries %>%
            select(-TIME, -year, -month) %>%
            summarise_all(prop_na) >  threshold
    
            # returns vector of station names to be excluded
            stations_to_exclude <- df_meta_region3$stationname[df1]
            return(stations_to_exclude)
            
  } else {
    
    # computes the proportion of NA values for each year for each station
    df1 <- timeseries %>%
            select(-TIME, -month) %>%
            group_by(year) %>%
            summarise_all(prop_na) %>%
            select(-year) > threshold
    
    # list which contains the years which should be removed for each station.
    years_to_exclude <- list()
    
    # fill the list
    for(station in 1:ncol(df1)) {
      
    df2 <- df1[, station]
    
            years_to_exclude_by_station <- unique(timeseries$year)[df2]
            years_to_exclude[[station]] <- years_to_exclude_by_station
    }
    
    names(years_to_exclude) <- df_meta_region3$stationname
    return(years_to_exclude)
  
  }
    
}

# returns stations that are missing more than 10% of their observations
overview_na(NOAA_OBS_Detided_region3, .1)
# for each station this returns the years that are missing more than 10% of their observations
overview_na(NOAA_OBS_Detided_region3, .1, T)
```

### Exploratory Data Analysis

*Interactive Map of Stations*

[kepler.gl](https://kepler.gl/demo/map?mapUrl=https://dl.dropboxusercontent.com/s/jdmoouleyema7z1/keplergl_s3tjnff.json)

```{r produce map of stations, warning = F}
states <- map_data("state")

east_coast <- states %>%
  filter(region %in% c('florida', 'georgia', 'south carolina', 'north carolina', 'virginia', 'district of columbia', 'pennsylvania', 'maryland', 'delaware', 'new jersey', 'connecticut', 'new york', 'rhode island', 'massachusetts', 'vermont', 'new hampshire', 'maine' ))

ggplot() + 
  geom_polygon(data = east_coast, aes(x = long, y = lat, group = group, fill = group), color = "white") +
  geom_point(data = df_meta_region3, aes(x = lon, y = lat), col = 'black', size = .8) +
  geom_text(data = df_meta_region3, aes(x = lon, y = lat, label = stationname), size = 2.5, col = 'red') +
  guides(fill = F) +
  theme_nothing()
```

*1. ADCIRC_POST_Detided*

```{r examine time-series, cache = T}
# plot timer-series for each station in FEMA region 3 simultaneously over specified time-interval
ADC_POST_Detided_region3 %>%
  filter('1979-01-01 0:00:00' <= TIME, TIME <= '1980-01-01 0:00:00') %>%
  melt(id.vars = c('TIME', 'year', 'month')) %>%
  ggplot(aes(x = TIME, y = value)) +
  geom_line(alpha = 0.5, col = 'blue', size = 0.1) +
  theme(axis.text.x = element_blank()) +
  facet_wrap(~variable)

# plot side-by-side box plots and violin plots for each station
ADC_POST_Detided_region3 %>%
  select(-TIME, -year, -month) %>%
  melt() %>%
  ggplot(aes(x = value, y = variable)) +
  geom_boxplot(outlier.size = 0.1)

ADC_POST_Detided_region3 %>%
  select(-TIME, -year, -month) %>%
  melt() %>%
  ggplot(aes(x = value, y = variable)) +
  geom_violin()

ADC_POST_Detided_region3 %>%
  melt(id.vars = c('TIME', 'year', 'month')) %>%
  ggplot(aes(x = value)) +
  geom_histogram(color = 'light blue') +
  facet_wrap(~variable)

ADC_POST_Detided_region3 %>%
  melt(id.vars = c('TIME', 'year', 'month')) %>%
  ggplot(aes(x = value)) +
  geom_density(color = 'light blue') +
  facet_wrap(~variable)
```

*2. Yearly maxima of ADCIRC POST Detided*

```{r create yearly maxima time-series}
# create data frame with yearly maxima for each station
 df_max <- ADC_POST_Detided_region3 %>% 
  select(-TIME, -month) %>%
  group_by(year) %>%
  summarise_all(max, na.rm = T)

# change year from class character to numeric
df_max <- df_max %>%
  mutate(year = as.numeric(year))

# compute block maxima for given station using only those years which the proportion of NAs are < threshold
max_timeseries <- function(timeseries, threshold) {
  
  timeseries_na <- overview_na(timeseries, threshold, T)
  results <- list()
  
for(station in colnames(timeseries[, 4:ncol(timeseries)])) {
  
  df <- timeseries %>%
      select(year, station) %>%
      filter(!year %in% timeseries_na$station) %>%
      drop_na() %>%
      group_by(year) %>%
      summarise(max = max(eval(as.name(station))))
  
  results[[station]] <- df
}
  return(results)
}

ADC_POST_Detided_max <- max_timeseries(ADC_POST_Detided_region3, threshold = 0.1)
NOAA_OBS_Detided_max <- max_timeseries(NOAA_OBS_Detided_region3, threshold = 0.1)

# visualize the block-maxima through time-seires, box plots, violin plots, histograms and density plots.
df_max %>%
  as.tibble() %>%
  melt(id.vars = c('year')) %>%
  ggplot(aes(x = year, y = value)) +
  geom_line(col = 'light blue') +
  facet_wrap(~variable)

df_max %>%
  select(-year) %>%
  melt() %>%
  ggplot(aes(x = value, y = variable)) +
  geom_boxplot(outlier.size = 0.01) 

df_max %>%
  select(-year) %>%
  melt() %>%
  ggplot(aes(x = value, y = variable)) +
  geom_violin() 

df_max %>%
  as.tibble() %>%
  melt(id.vars = c('year')) %>%
  ggplot(aes(x = value)) +
  geom_histogram(col = 'light blue') +
  facet_wrap(~variable)

df_max %>%
  as.tibble() %>%
  melt(id.vars = c('year')) %>%
  ggplot(aes(x = value)) +
  geom_density(col = 'light blue') +
  facet_wrap(~variable)
```

### Statistical Modeling

```{r return level plots}
# compute return levels associated with return period 1/p
gev_results <- function(p, gev) {

  gev_param <- gev$results$par
  
  y_p <- -log(1 - p)
  
  # compute return level associated with return period 1/p
  if(gev_param[3] == 0) {
    
    rl <- as.numeric(gev_param[1] - gev_param[2]*log(y_p))
    
  } else {
    rl <-as.numeric(gev_param[1] - (gev_param[2]/gev_param[3])*(1 - y_p^-gev_param[3]))
  }
  
  # compute gradient of return level associated with return period 1/p
  rl_grad <- c(1, (-gev_param[3]^-1)*(1 - y_p^-gev_param[3]), gev_param[2]*(gev_param[3]^-2)*(1 - y_p^-gev_param[3]) - gev_param[2]*(gev_param[3]^-1)*(y_p^-gev_param[3])*log(y_p))
  
  # compute variance matrix of return level associated with return period 1/p via delta method
  gev_cov <- solve(gev$results$hessian)
  rl_var <-  t(rl_grad) %*% gev_cov %*% rl_grad
  
  result <- c(rl, rl_var)
  
  
  return(result)
  
}

# generate return level plot over given return period sequence
gev_rl_plot <- function(periods, gev, alpha, station_name) {
  
rl <- vector()
ci_upper <- vector()
ci_lower <- vector()

for(i in 1:length(periods)) {
  
  rl[i] <- gev_results(periods[i], gev)[1]
  ci_upper[i] <- rl[i] + qnorm(1 - alpha/2)*sqrt(gev_results(periods[i], gev)[2])
  ci_lower[i] <- rl[i] - qnorm(1 - alpha/2)*sqrt(gev_results(periods[i], gev)[2])

}

p <- data.frame(y_p = -1/log(1 - periods), rl = rl, ci_upper = ci_upper, ci_lower = ci_lower) %>%
  ggplot() +
  scale_x_log10() +
  geom_line(aes(x = y_p, y = rl), color = 'light blue') +
  geom_line(aes(x = y_p, y = ci_upper), color = 'green', linetype = 'dashed') +
  geom_line(aes(x = y_p, y = ci_lower), color = 'green', linetype = 'dashed') +
  labs(title = station_name, y = 'return level')

return(p)

}

# specify return period sequence
periods <- seq(1/1000, 1/2, length.out = 100)[100:1]

# generate return level plot for each station

for(i in 2:27) {
  
gev <- fevd(df_max[[i]], type = 'GEV')

print(gev_rl_plot(periods, gev, 0.05, labels(df_max)[[2]][i]))

}

for(i in 2:27) {
gev <- fevd(df_max[[i]], type = 'GEV')
plot(gev, type = 'rl', main = labels(df_max)[[2]][i])
}
```

